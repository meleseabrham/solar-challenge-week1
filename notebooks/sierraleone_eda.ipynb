{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sierra Leone EDA Notebook\n",
        "# Objective: Profile, clean, and explore Sierra Leone's solar dataset end-to-end with metric-specific outlier detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sierra Leone EDA - Setup and Imports\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from pathlib import Path\n",
        "\n",
        "# Add parent directories to path for utility imports\n",
        "sys.path.append(str(Path(__file__).resolve().parents[2]))\n",
        "from app.utils import (\n",
        "    detect_outliers_ghi,\n",
        "    detect_outliers_dni,\n",
        "    detect_outliers_dhi,\n",
        "    detect_solar_metric_outliers,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "COUNTRY = \"sierraleone\"\n",
        "DATA_DIR = Path(\"../data\").resolve()\n",
        "RAW_DATA_PATH = DATA_DIR / \"sierraleone-bumbuna.csv\"\n",
        "CLEAN_DATA_PATH = DATA_DIR / \"sierraleone_clean.csv\"\n",
        "\n",
        "# Columns of interest\n",
        "NUMERIC_CANDIDATES: List[str] = [\n",
        "    \"GHI\", \"DNI\", \"DHI\", \"Tamb\", \"TModA\", \"TModB\",\n",
        "    \"ModA\", \"ModB\", \"WS\", \"WSgust\", \"WD\", \"RH\", \"BP\"\n",
        "]\n",
        "TIME_COLUMN_CANDIDATES: List[str] = [\"Timestamp\", \"timestamp\", \"time\", \"Date\", \"Datetime\"]\n",
        "CLEANING_FLAG_CANDIDATES: List[str] = [\"Cleaning\", \"cleaned\", \"is_cleaned\"]\n",
        "\n",
        "def find_first_column(df: pd.DataFrame, candidates: List[str]) -> str | None:\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def existing_columns(df: pd.DataFrame, cols: List[str]) -> List[str]:\n",
        "    return [c for c in cols if c in df.columns]\n",
        "\n",
        "print(f\"Expecting raw CSV at: {RAW_DATA_PATH}\")\n",
        "if not RAW_DATA_PATH.exists():\n",
        "    print(\"WARNING: Raw data file not found. Place the CSV at:\", RAW_DATA_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "try:\n",
        "    df = pd.read_csv(RAW_DATA_PATH)\n",
        "    print(\"Loaded:\", df.shape)\n",
        "    # Try to parse a timestamp column if present\n",
        "    time_col = find_first_column(df, TIME_COLUMN_CANDIDATES)\n",
        "    if time_col is not None:\n",
        "        df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
        "        df = df.sort_values(by=time_col)\n",
        "    else:\n",
        "        print(\"No time-like column found in:\", TIME_COLUMN_CANDIDATES)\n",
        "except FileNotFoundError:\n",
        "    df = pd.DataFrame()\n",
        "    print(\"Data not found. Proceed to place the CSV and re-run this cell.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic profile: head, info, dtypes\n",
        "if not df.empty:\n",
        "    display(df.head())\n",
        "    display(df.tail())\n",
        "    print(\"\\nData types:\\n\", df.dtypes)\n",
        "    print(\"\\nShape:\", df.shape)\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics & missing-value report\n",
        "if not df.empty:\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    display(df[num_cols].describe().T)\n",
        "\n",
        "    na_series = df.isna().sum().sort_values(ascending=False)\n",
        "    na_pct = (na_series / len(df) * 100).round(2)\n",
        "    missing_report = pd.DataFrame({\"missing\": na_series, \"%\": na_pct})\n",
        "    display(missing_report[missing_report[\"%\"] > 0])\n",
        "\n",
        "    gt5 = missing_report[missing_report[\"%\"] > 5]\n",
        "    if not gt5.empty:\n",
        "        print(\"Columns with >5% nulls:\")\n",
        "        display(gt5)\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metric-specific outlier detection for GHI, DNI, DHI\n",
        "if not df.empty:\n",
        "    print(\"=\"*60)\n",
        "    print(\"METRIC-SPECIFIC OUTLIER DETECTION\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Apply metric-specific outlier detection\n",
        "    outlier_flags, combined_mask = detect_solar_metric_outliers(df)\n",
        "    \n",
        "    # Report findings for each metric\n",
        "    for metric in [\"GHI\", \"DNI\", \"DHI\"]:\n",
        "        if metric in df.columns:\n",
        "            outlier_col = f\"{metric}_outlier\"\n",
        "            if outlier_col in outlier_flags.columns:\n",
        "                outlier_count = outlier_flags[outlier_col].sum()\n",
        "                outlier_pct = (outlier_count / len(df) * 100).round(2)\n",
        "                print(f\"\\n{metric}:\")\n",
        "                print(f\"  Outliers detected: {outlier_count} ({outlier_pct}%)\")\n",
        "                \n",
        "                # Show statistics for outliers vs non-outliers\n",
        "                if outlier_count > 0:\n",
        "                    normal_values = df.loc[~outlier_flags[outlier_col], metric]\n",
        "                    outlier_values = df.loc[outlier_flags[outlier_col], metric]\n",
        "                    print(f\"  Normal range: {normal_values.min():.1f} - {normal_values.max():.1f} W/m²\")\n",
        "                    print(f\"  Outlier range: {outlier_values.min():.1f} - {outlier_values.max():.1f} W/m²\")\n",
        "    \n",
        "    print(f\"\\nTotal rows with any outlier: {combined_mask.sum()} ({combined_mask.sum()/len(df)*100:.2f}%)\")\n",
        "    \n",
        "    # Add outlier flags to dataframe for visualization\n",
        "    for col in outlier_flags.columns:\n",
        "        df[col] = outlier_flags[col]\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create cleaned dataset with median imputation\n",
        "if not df.empty:\n",
        "    cleaned = df.copy()\n",
        "    key_cols = existing_columns(cleaned, [\"GHI\", \"DNI\", \"DHI\", \"ModA\", \"ModB\", \"WS\", \"WSgust\"])\n",
        "    for c in key_cols:\n",
        "        if cleaned[c].isna().any():\n",
        "            median_val = cleaned[c].median()\n",
        "            cleaned[c] = cleaned[c].fillna(median_val)\n",
        "            print(f\"Imputed {c}: {cleaned[c].isna().sum()} → 0 missing (median: {median_val:.2f})\")\n",
        "    \n",
        "    display(cleaned[key_cols].describe().T)\n",
        "    \n",
        "    # Store for export\n",
        "    cleaned_df = cleaned\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export cleaned dataset\n",
        "def export_clean(df_original: pd.DataFrame) -> None:\n",
        "    if df_original.empty:\n",
        "        print(\"Empty DataFrame; skipping export.\")\n",
        "        return\n",
        "    cleaned = df_original.copy()\n",
        "    key_cols = existing_columns(cleaned, [\"GHI\", \"DNI\", \"DHI\", \"ModA\", \"ModB\", \"WS\", \"WSgust\"])\n",
        "    for c in key_cols:\n",
        "        cleaned[c] = cleaned[c].fillna(cleaned[c].median())\n",
        "\n",
        "    os.makedirs(os.path.dirname(CLEAN_DATA_PATH), exist_ok=True)\n",
        "    cleaned.to_csv(CLEAN_DATA_PATH, index=False)\n",
        "    print(\"Exported cleaned CSV to:\", CLEAN_DATA_PATH)\n",
        "\n",
        "if 'cleaned_df' in globals() and not cleaned_df.empty:\n",
        "    export_clean(cleaned_df)\n",
        "else:\n",
        "    print(\"No cleaned data to export.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time series analysis: GHI, DNI, DHI, Tamb vs time\n",
        "if not df.empty:\n",
        "    tcol = find_first_column(df, TIME_COLUMN_CANDIDATES)\n",
        "    if tcol is not None and pd.api.types.is_datetime64_any_dtype(df[tcol]):\n",
        "        ts_cols = existing_columns(df, [\"GHI\", \"DNI\", \"DHI\", \"Tamb\"])\n",
        "        if ts_cols:\n",
        "            fig, axes = plt.subplots(len(ts_cols), 1, figsize=(14, 3.2*len(ts_cols)), sharex=True)\n",
        "            if len(ts_cols) == 1:\n",
        "                axes = [axes]\n",
        "            for ax, c in zip(axes, ts_cols):\n",
        "                ax.plot(df[tcol], df[c], label=c, alpha=0.7)\n",
        "                ax.set_ylabel(c)\n",
        "                ax.legend(loc=\"upper right\")\n",
        "            axes[-1].set_xlabel(tcol)\n",
        "            plt.suptitle(\"Time Series: core variables - Sierra Leone\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No TS columns among:\", [\"GHI\", \"DNI\", \"DHI\", \"Tamb\"])    \n",
        "    else:\n",
        "        print(\"Time column not found or not datetime; skipping TS plots.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution boxplots for GHI, DNI, DHI\n",
        "if not df.empty:\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=False)\n",
        "    for ax, metric in zip(axes, [\"GHI\", \"DNI\", \"DHI\"]):\n",
        "        if metric in df.columns:\n",
        "            sns.boxplot(data=df, y=metric, ax=ax, color=\"#60a5fa\")\n",
        "            ax.set_title(f\"{metric} distribution - Sierra Leone\")\n",
        "            ax.set_ylabel(f\"{metric} (W/m²)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "if not df.empty:\n",
        "    corr_cols = existing_columns(df, [\"GHI\", \"DNI\", \"DHI\", \"TModA\", \"TModB\", \"Tamb\", \"WS\", \"WSgust\", \"RH\"])\n",
        "    if corr_cols:\n",
        "        corr = df[corr_cols].corr()\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, center=0)\n",
        "        plt.title(\"Correlation Heatmap - Sierra Leone\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No numeric columns for correlation heatmap.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots: WS, WSgust, WD vs GHI; RH vs Tamb & GHI\n",
        "if not df.empty:\n",
        "    pairs = [\n",
        "        (\"WS\", \"GHI\"), (\"WSgust\", \"GHI\"), (\"WD\", \"GHI\"),\n",
        "        (\"RH\", \"Tamb\"), (\"RH\", \"GHI\")\n",
        "    ]\n",
        "    pairs = [(x, y) for (x, y) in pairs if x in df.columns and y in df.columns]\n",
        "    if pairs:\n",
        "        cols = 2\n",
        "        rows = int(np.ceil(len(pairs) / cols))\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows))\n",
        "        axes = np.atleast_1d(axes).ravel()\n",
        "        for ax, (x, y) in zip(axes, pairs):\n",
        "            sns.scatterplot(data=df, x=x, y=y, s=10, alpha=0.4, ax=ax)\n",
        "            sns.regplot(data=df, x=x, y=y, scatter=False, color='red', ax=ax)\n",
        "            ax.set_title(f\"{x} vs {y} - Sierra Leone\")\n",
        "        for ax in axes[len(pairs):]:\n",
        "            ax.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No valid pairs for scatter plots.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histograms for GHI, DNI, DHI\n",
        "if not df.empty:\n",
        "    hcols = existing_columns(df, [\"GHI\", \"DNI\", \"DHI\"])\n",
        "    if hcols:\n",
        "        fig, axes = plt.subplots(1, len(hcols), figsize=(5*len(hcols), 4))\n",
        "        if len(hcols) == 1:\n",
        "            axes = [axes]\n",
        "        for ax, col in zip(axes, hcols):\n",
        "            df[col].hist(bins=50, ax=ax, color=\"#60a5fa\", alpha=0.7)\n",
        "            ax.set_title(f\"{col} Histogram - Sierra Leone\")\n",
        "            ax.set_xlabel(f\"{col} (W/m²)\")\n",
        "            ax.set_ylabel(\"Frequency\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No histogram columns present.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleaning impact: average ModA & ModB by Cleaning flag (if available)\n",
        "if not df.empty:\n",
        "    flag_col = find_first_column(df, CLEANING_FLAG_CANDIDATES)\n",
        "    target_cols = existing_columns(df, [\"ModA\", \"ModB\"])\n",
        "    if flag_col and target_cols:\n",
        "        grp = df.groupby(flag_col)[target_cols].mean().rename_axis(flag_col)\n",
        "        display(grp)\n",
        "        grp.plot(kind=\"bar\", figsize=(8, 4), title=\"Average ModA/ModB by Cleaning flag - Sierra Leone\")\n",
        "        plt.ylabel(\"Average\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Cleaning flag or target cols not present; skipping.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
