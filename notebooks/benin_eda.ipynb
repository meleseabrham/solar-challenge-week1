{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Benin EDA Notebook\n",
        "# Objective: Profile, clean, and explore Benin's solar dataset end-to-end.\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "COUNTRY = \"benin\"\n",
        "RAW_DATA_PATH = os.path.join(\"..\", \"data\", f\"{COUNTRY}.csv\")\n",
        "CLEAN_DATA_PATH = os.path.join(\"..\", \"data\", f\"{COUNTRY}_clean.csv\")\n",
        "\n",
        "# Columns of interest (use what exists in the dataset)\n",
        "NUMERIC_CANDIDATES: List[str] = [\n",
        "    \"GHI\", \"DNI\", \"DHI\", \"Tamb\", \"TModA\", \"TModB\",\n",
        "    \"ModA\", \"ModB\", \"WS\", \"WSgust\", \"WD\", \"RH\", \"BP\"\n",
        "]\n",
        "TIME_COLUMN_CANDIDATES: List[str] = [\"Timestamp\", \"timestamp\", \"time\", \"Date\", \"Datetime\"]\n",
        "CLEANING_FLAG_CANDIDATES: List[str] = [\"Cleaning\", \"cleaned\", \"is_cleaned\"]\n",
        "\n",
        "def find_first_column(df: pd.DataFrame, candidates: List[str]) -> str | None:\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def existing_columns(df: pd.DataFrame, cols: List[str]) -> List[str]:\n",
        "    return [c for c in cols if c in df.columns]\n",
        "\n",
        "print(f\"Expecting raw CSV at: {RAW_DATA_PATH}\")\n",
        "if not os.path.exists(RAW_DATA_PATH):\n",
        "    print(\"WARNING: Raw data file not found. Place the country's CSV at:\", RAW_DATA_PATH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "try:\n",
        "    df = pd.read_csv(RAW_DATA_PATH)\n",
        "    print(\"Loaded:\", df.shape)\n",
        "    # Try to parse a timestamp column if present\n",
        "    time_col = find_first_column(df, TIME_COLUMN_CANDIDATES)\n",
        "    if time_col is not None:\n",
        "        df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
        "        df = df.sort_values(by=time_col)\n",
        "    else:\n",
        "        print(\"No time-like column found in:\", TIME_COLUMN_CANDIDATES)\n",
        "except FileNotFoundError:\n",
        "    df = pd.DataFrame()\n",
        "    print(\"Data not found. Proceed to place the CSV and re-run this cell.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic profile: head, info, dtypes\n",
        "if not df.empty:\n",
        "    display(df.head())\n",
        "    display(df.tail())\n",
        "    print(\"\\nData types:\\n\", df.dtypes)\n",
        "    print(\"\\nShape:\", df.shape)\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics & missing-value report\n",
        "if not df.empty:\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    display(df[num_cols].describe().T)\n",
        "\n",
        "    na_series = df.isna().sum().sort_values(ascending=False)\n",
        "    na_pct = (na_series / len(df) * 100).round(2)\n",
        "    missing_report = pd.DataFrame({\"missing\": na_series, \"%\": na_pct})\n",
        "    display(missing_report[missing_report[\"%\"] > 0])\n",
        "\n",
        "    gt5 = missing_report[missing_report[\"%\"] > 5]\n",
        "    if not gt5.empty:\n",
        "        print(\"Columns with >5% nulls:\")\n",
        "        display(gt5)\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Outlier detection via Z-scores and basic cleaning\n",
        "if not df.empty:\n",
        "    cols_to_check = existing_columns(df, [\n",
        "        \"GHI\", \"DNI\", \"DHI\", \"ModA\", \"ModB\", \"WS\", \"WSgust\"\n",
        "    ])\n",
        "    print(\"Columns considered for Z-score outliers:\", cols_to_check)\n",
        "\n",
        "    z_df = pd.DataFrame(index=df.index)\n",
        "    for c in cols_to_check:\n",
        "        series = df[c].astype(float)\n",
        "        z = stats.zscore(series, nan_policy='omit')\n",
        "        z_df[c] = z\n",
        "\n",
        "    # Flag rows with any |Z| > 3\n",
        "    z_flag = (z_df.abs() > 3).any(axis=1)\n",
        "    print(\"Potential outliers (any |Z|>3):\", int(z_flag.sum()))\n",
        "\n",
        "    # Create cleaned copy with median imputation for key columns\n",
        "    cleaned = df.copy()\n",
        "    key_cols = existing_columns(cleaned, [\"GHI\", \"DNI\", \"DHI\", \"ModA\", \"ModB\", \"WS\", \"WSgust\"])\n",
        "    for c in key_cols:\n",
        "        if cleaned[c].isna().any():\n",
        "            cleaned[c] = cleaned[c].fillna(cleaned[c].median())\n",
        "\n",
        "    display(cleaned[key_cols].describe().T)\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export cleaned dataset\n",
        "def export_clean(df_original: pd.DataFrame) -> None:\n",
        "    if df_original.empty:\n",
        "        print(\"Empty DataFrame; skipping export.\")\n",
        "        return\n",
        "    cleaned = df_original.copy()\n",
        "    key_cols = existing_columns(cleaned, [\"GHI\", \"DNI\", \"DHI\", \"ModA\", \"ModB\", \"WS\", \"WSgust\"])\n",
        "    for c in key_cols:\n",
        "        cleaned[c] = cleaned[c].fillna(cleaned[c].median())\n",
        "\n",
        "    os.makedirs(os.path.dirname(CLEAN_DATA_PATH), exist_ok=True)\n",
        "    cleaned.to_csv(CLEAN_DATA_PATH, index=False)\n",
        "    print(\"Exported cleaned CSV to:\", CLEAN_DATA_PATH)\n",
        "\n",
        "export_clean(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time series analysis: GHI, DNI, DHI, Tamb vs time\n",
        "if not df.empty:\n",
        "    tcol = find_first_column(df, TIME_COLUMN_CANDIDATES)\n",
        "    if tcol is not None and pd.api.types.is_datetime64_any_dtype(df[tcol]):\n",
        "        ts_cols = existing_columns(df, [\"GHI\", \"DNI\", \"DHI\", \"Tamb\"])\n",
        "        if ts_cols:\n",
        "            fig, axes = plt.subplots(len(ts_cols), 1, figsize=(14, 3.2*len(ts_cols)), sharex=True)\n",
        "            if len(ts_cols) == 1:\n",
        "                axes = [axes]\n",
        "            for ax, c in zip(axes, ts_cols):\n",
        "                ax.plot(df[tcol], df[c], label=c)\n",
        "                ax.set_ylabel(c)\n",
        "                ax.legend(loc=\"upper right\")\n",
        "            axes[-1].set_xlabel(tcol)\n",
        "            plt.suptitle(\"Time Series: core variables\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No TS columns among:\", [\"GHI\", \"DNI\", \"DHI\", \"Tamb\"])    \n",
        "    else:\n",
        "        print(\"Time column not found or not datetime; skipping TS plots.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleaning impact: average ModA & ModB by Cleaning flag\n",
        "if not df.empty:\n",
        "    flag_col = find_first_column(df, CLEANING_FLAG_CANDIDATES)\n",
        "    target_cols = existing_columns(df, [\"ModA\", \"ModB\"])\n",
        "    if flag_col and target_cols:\n",
        "        grp = df.groupby(flag_col)[target_cols].mean().rename_axis(flag_col)\n",
        "        display(grp)\n",
        "        grp.plot(kind=\"bar\", figsize=(8,4), title=\"Average ModA/ModB by Cleaning flag\")\n",
        "        plt.ylabel(\"Average\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Cleaning flag or target cols not present; skipping.\")\n",
        "else:\n",
        "    print(\"DataFrame is empty. Load data first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
